{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNdGbmkrlAxTkeGhxZhpXXF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wenqiglantz/edd-recursive-doc-agent-vs-metadata-replacement/blob/main/edd_recursive_doc_agent_metadata_replacement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Driven Development for Multi Document RAG Pipeline\n",
        "\n",
        "This notebook demonstrates how to use EDD to decide which of these two strategies perform best for a multi document RAG pipeline:\n",
        "\n",
        "\n",
        "*   Recursive retriever + document agent\n",
        "*   Metadata replacement + node sentence window\n",
        "\n"
      ],
      "metadata": {
        "id": "YTyvoKy7zbUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index==0.8.40 pypdf sentence-transformers"
      ],
      "metadata": {
        "id": "gZhtMcUkhCRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import (\n",
        "    VectorStoreIndex,\n",
        "    SummaryIndex,\n",
        "    SimpleKeywordTableIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        ")\n",
        "from llama_index.schema import IndexNode\n",
        "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.llms import OpenAI"
      ],
      "metadata": {
        "id": "IyMTf5zBjlaI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, openai, logging, sys\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-#####################\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)"
      ],
      "metadata": {
        "id": "9WMxhw2Yjpjs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Common Tasks"
      ],
      "metadata": {
        "id": "T4lm3s7TVQSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load documents"
      ],
      "metadata": {
        "id": "yoLvyqElVEYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titles = [\n",
        "    \"DevOps_Self-Service_Pipeline_Architecture\",\n",
        "    \"DevOps_Self-Service_Terraform_Project_Structure\",\n",
        "    \"DevOps_Self-Service_Pipeline_Security_Guardrails\"\n",
        "    ]\n",
        "\n",
        "documents = {}\n",
        "for title in titles:\n",
        "    documents[title] = SimpleDirectoryReader(input_files=[f\"./data/{title}.pdf\"]).load_data()\n",
        "print(f\"loaded documents with {len(documents)} documents\")"
      ],
      "metadata": {
        "id": "YSe_WBU9j3ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9107f304-5c82-4b19-c9fb-467e4d14b2aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded documents with 3 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recursive retriever + document agent"
      ],
      "metadata": {
        "id": "1Y9qfIIEzVSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import (\n",
        "    VectorStoreIndex,\n",
        "    ListIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        "    Response\n",
        ")\n",
        "from llama_index.evaluation import (\n",
        "    DatasetGenerator,\n",
        "    QueryResponseEvaluator,\n",
        "    ResponseEvaluator\n",
        ")\n",
        "from llama_index.retrievers import RecursiveRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index.response_synthesizers import get_response_synthesizer\n",
        "from llama_index.schema import IndexNode\n",
        "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.llms import OpenAI\n",
        "from llama_index.agent import OpenAIAgent\n",
        "import pandas as pd\n",
        "import openai\n",
        "import os"
      ],
      "metadata": {
        "id": "8oVgXUbnzYO8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define LLM\n",
        "llm = OpenAI(temperature=0.1, model_name=\"gpt-3.5-turbo\")\n",
        "service_context = ServiceContext.from_defaults(llm=llm)"
      ],
      "metadata": {
        "id": "An74pufeQSQV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create document agents"
      ],
      "metadata": {
        "id": "qLSEFZGZYBrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build agents dictionary\n",
        "agents = {}\n",
        "\n",
        "for title in titles:\n",
        "\n",
        "    # build vector index\n",
        "    vector_index = VectorStoreIndex.from_documents(documents[title], service_context=service_context)\n",
        "\n",
        "    # build list index\n",
        "    list_index = ListIndex.from_documents(documents[title], service_context=service_context)\n",
        "\n",
        "    # define query engines\n",
        "    vector_query_engine = vector_index.as_query_engine()\n",
        "    list_query_engine = list_index.as_query_engine()\n",
        "\n",
        "    # define tools\n",
        "    query_engine_tools = [\n",
        "        QueryEngineTool(\n",
        "            query_engine=vector_query_engine,\n",
        "            metadata=ToolMetadata(\n",
        "                name=\"vector_tool\",\n",
        "                description=f\"Useful for retrieving specific context related to {title}\",\n",
        "            ),\n",
        "        ),\n",
        "        QueryEngineTool(\n",
        "            query_engine=list_query_engine,\n",
        "            metadata=ToolMetadata(\n",
        "                name=\"summary_tool\",\n",
        "                description=f\"Useful for summarization questions related to {title}\",\n",
        "            ),\n",
        "        ),\n",
        "    ]\n",
        "\n",
        "    # build agent\n",
        "    function_llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
        "    agent = OpenAIAgent.from_tools(\n",
        "        query_engine_tools,\n",
        "        llm=function_llm,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "    agents[title] = agent"
      ],
      "metadata": {
        "id": "ZqQEKsHYQW4p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create index nodes"
      ],
      "metadata": {
        "id": "6xpBE3mGYKIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define index nodes that link to the document agents\n",
        "nodes = []\n",
        "for title in titles:\n",
        "    doc_summary = (\n",
        "        f\"This content contains details about {title}. \"\n",
        "        f\"Use this index if you need to lookup specific facts about {title}.\\n\"\n",
        "        \"Do not use this index if you want to query multiple documents.\"\n",
        "    )\n",
        "    node = IndexNode(text=doc_summary, index_id=title)\n",
        "    nodes.append(node)\n",
        "\n",
        "# define retriever\n",
        "vector_index = VectorStoreIndex(nodes)\n",
        "vector_retriever = vector_index.as_retriever(similarity_top_k=1)"
      ],
      "metadata": {
        "id": "l3wSCxsvQopB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define recursive retriever and query engine"
      ],
      "metadata": {
        "id": "z4T3rjq7YPgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define recursive retriever\n",
        "# note: can pass `agents` dict as `query_engine_dict` since every agent can be used as a query engine\n",
        "recursive_retriever = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever},\n",
        "    query_engine_dict=agents,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "response_synthesizer = get_response_synthesizer(response_mode=\"compact\")\n",
        "\n",
        "# define query engine\n",
        "recursive_query_engine = RetrieverQueryEngine.from_args(\n",
        "    recursive_retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        "    service_context=service_context,\n",
        ")"
      ],
      "metadata": {
        "id": "FY27l9WBYU6F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run test queries"
      ],
      "metadata": {
        "id": "pBcK9d-sYYeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = recursive_query_engine.query(\"Give me a summary of DevOps self-service-centric pipeline security and guardrails.\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxUa5-t7Qr-5",
        "outputId": "29b99781-00a7-490d-8fdd-2e667ef8d5ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DevOps self-service-centric pipeline security and guardrails are essential components of a secure and efficient DevOps practice. These practices involve implementing security measures and guardrails within the centralized repository that hosts reusable workflows and modules.\n",
            "\n",
            "One tool that can assist in pipeline security is Trivy, an open-source security scanner. Trivy scans container images for known vulnerabilities in the operating system packages and libraries they use. It can be easily integrated into your CI/CD workflow and provides fast and comprehensive vulnerability scanning.\n",
            "\n",
            "By customizing the scan parameters, you can focus on specific vulnerability types and severity levels, allowing you to prioritize and address critical security risks effectively. Regularly scanning container images helps ensure that pipelines are free from known vulnerabilities, reducing the risk of security breaches.\n",
            "\n",
            "Implementing self-service-centric pipeline security and guardrails ensures the integrity and safety of pipelines, enabling the delivery of secure and reliable software products to customers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = recursive_query_engine.query(\"What is Harden Runner in DevOps self-service-centric pipeline security and guardrails?\")\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hspa0axrRFlf",
        "outputId": "f673daf5-fb8d-4597-cbc4-2564f822e419"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harden Runner in DevOps self-service-centric pipeline security and guardrails refers to the process of securing the runner environment used in CI/CD pipelines. It involves implementing security measures to protect the runner environment from potential vulnerabilities and attacks. This includes configuring access controls, applying security patches and updates, using secure communication protocols, and implementing security monitoring and logging. By hardening the runner environment, organizations can ensure that the execution of CI/CD pipelines is done in a secure and controlled manner, reducing the risk of unauthorized access, data breaches, and other security incidents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metadata Replacement + Node Sentence Window"
      ],
      "metadata": {
        "id": "CH_ujQmGC47N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up node parser, service context"
      ],
      "metadata": {
        "id": "-Z0aWGmRYxwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext, set_global_service_context\n",
        "from llama_index.llms import OpenAI\n",
        "from llama_index.embeddings import OpenAIEmbedding, HuggingFaceEmbedding\n",
        "from llama_index.node_parser import SentenceWindowNodeParser, SimpleNodeParser\n",
        "\n",
        "# create the sentence window node parser\n",
        "node_parser = SentenceWindowNodeParser.from_defaults(\n",
        "    window_size=3,\n",
        "    window_metadata_key=\"window\",\n",
        "    original_text_metadata_key=\"original_text\",\n",
        ")\n",
        "simple_node_parser = SimpleNodeParser.from_defaults()\n",
        "\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
        "embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"sentence-transformers/all-mpnet-base-v2\", max_length=512\n",
        ")\n",
        "ctx = ServiceContext.from_defaults(\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "J8LuDoOeC4Rs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract nodes and build index"
      ],
      "metadata": {
        "id": "xtKcJHVEYmg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex\n",
        "\n",
        "document_list = SimpleDirectoryReader(\"data\").load_data()\n",
        "nodes = node_parser.get_nodes_from_documents(document_list)\n",
        "sentence_index = VectorStoreIndex(nodes, service_context=ctx)"
      ],
      "metadata": {
        "id": "GgzwUWmqDF5t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define query engine"
      ],
      "metadata": {
        "id": "FAjUYkemZJ2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
        "\n",
        "metadata_query_engine = sentence_index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    # the target key defaults to `window` to match the node_parser's default\n",
        "    node_postprocessors=[\n",
        "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "8n-aSz1jDYy3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run test queries"
      ],
      "metadata": {
        "id": "Zd1c8by0ZRJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Give me a summary of DevOps self-service-centric pipeline security and guardrails.\"\n",
        "response = metadata_query_engine.query(query)\n",
        "print(str(response))"
      ],
      "metadata": {
        "id": "GL2cEx1FDfQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142908ed-807d-4b8c-eac3-568c8bd80607"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DevOps self-service-centric pipeline security and guardrails involve implementing a list of hand-picked actions to ensure the security and compliance of pipelines, infrastructure, source code, base images, and dependent libraries. These actions are implemented in reusable workflows for both infrastructure and application pipelines, and developers are expected to adhere to them when developing workflows for their applications. The goal is to provide a self-service environment where developers can confidently build and deploy their applications while maintaining the necessary security measures.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Harden Runner in DevOps self-service-centric pipeline security and guardrails?\"\n",
        "response = metadata_query_engine.query(query)\n",
        "print(str(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRlbdpYCFwlC",
        "outputId": "da7ce0bf-7b32-47ab-c994-df3b00b6ba3e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harden-Runner is a purpose-built security monitoring agent for pipelines in DevOps self-service-centric pipeline security and guardrails. It is designed to detect and prevent malicious patterns that have been observed during past software supply chain security breaches. Some of the main features of Harden-Runner include automatically discovering and correlating outbound traffic with each step in the pipeline, preventing the exfiltration of credentials, and detecting tampering of source code during the build process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluations"
      ],
      "metadata": {
        "id": "SVlkfNvMW0pA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define evaluators"
      ],
      "metadata": {
        "id": "Cbouoes9r1M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.evaluation import FaithfulnessEvaluator, RelevancyEvaluator\n",
        "\n",
        "# use gpt-4 to evaluate\n",
        "gpt4_service_context = ServiceContext.from_defaults(llm=OpenAI(temperature=0.1, llm=\"gpt-4\"))\n",
        "\n",
        "faithfulness_gpt4 = FaithfulnessEvaluator(service_context=gpt4_service_context)\n",
        "relevancy_gpt4 = RelevancyEvaluator(service_context=gpt4_service_context)"
      ],
      "metadata": {
        "id": "LtE78hi_hlzs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate evaluation questions"
      ],
      "metadata": {
        "id": "041LeIE-r5PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "from llama_index.evaluation import DatasetGenerator\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# load data\n",
        "document_list = SimpleDirectoryReader(\"data\").load_data()\n",
        "\n",
        "question_dataset = []\n",
        "if os.path.exists(\"question_dataset.txt\"):\n",
        "    with open(\"question_dataset.txt\", \"r\") as f:\n",
        "        for line in f:\n",
        "            question_dataset.append(line.strip())\n",
        "else:\n",
        "    # generate questions\n",
        "    data_generator = DatasetGenerator.from_documents(document_list)\n",
        "    generated_questions = data_generator.generate_questions_from_nodes()\n",
        "    print(f\"Generated {len(generated_questions)} questions.\")\n",
        "\n",
        "    # randomly pick 30 questions\n",
        "    generated_questions = random.sample(generated_questions, 30)\n",
        "    question_dataset.extend(generated_questions)\n",
        "    print(f\"Randomly picked {len(question_dataset)} questions.\")\n",
        "\n",
        "    # save the questions into a txt file\n",
        "    with open(\"question_dataset.txt\", \"w\") as f:\n",
        "        for question in question_dataset:\n",
        "            f.write(f\"{question.strip()}\\n\")\n",
        "\n",
        "for i, question in enumerate(question_dataset, start=1):\n",
        "    print(f\"{i}. {question}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMFJhOCqgwk0",
        "outputId": "6466d52c-90c7-49f2-ae42-e140fc390842"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. What is the high-level design of DevOps pipelines?\n",
            "2. What is a recently introduced feature in Infracost Cloud?\n",
            "3. What is the purpose of Infracost in cloud cost management?\n",
            "4. Why is it important to include TruffleHog in your pipelines?\n",
            "5. How can you fix the vulnerability in the base image according to the provided instructions?\n",
            "6. What is the purpose of the aquasecurity/trivy-action in the GitHub Actions CI workflow?\n",
            "7. What are the optional parameters that can be used with the Checkov action?\n",
            "8. How can Infracost be integrated into the infrastructure pipeline?\n",
            "9. How are application pipelines triggered?\n",
            "10. Give me a summary of DevOps Self-Service Pipeline Architecture and Its 3–2–1 Rule.\n",
            "11. What command is used to generate the Infracost report in HTML format?\n",
            "12. How does Terraform enable the creation of reusable infrastructure?\n",
            "13. How can the GitHub Actions workflow be configured to dynamically select the backend configuration file based on the environment?\n",
            "14. What is the diff feature in Infracost and how does it serve as a guardrail for cloud cost management?\n",
            "15. How does Infracost provide a safety net for catching abnormal cloud cost estimates?\n",
            "16. What is the purpose of uploading the report to an artifact?\n",
            "17. What types of files or systems can Trivy scan?\n",
            "18. What severity levels does Trivy consider for vulnerabilities?\n",
            "19. What is the purpose of the Terraform GitHub Actions workflow?\n",
            "20. Can you provide a link to a website that provides information on creating Terraform modules?\n",
            "21. What is the intended audience for these documents?\n",
            "22. What is the purpose of the \"DevOps Self-Service -Centric GitHub Actions’ Workflow Orchestration\" article?\n",
            "23. What is the purpose of the \"--soft-fail\" flag in the TFSec step of the workflow?\n",
            "24. Give me a summary of DevOps self-service-centric pipeline security and guardrails.\n",
            "25. What command is used to initialize Terraform with a specific backend configuration file?\n",
            "26. What information can Trivy find during a scan?\n",
            "27. What CLI configuration files should be ignored?\n",
            "28. What is the purpose of Terraform as an Infrastructure as Code (IaC) tool?\n",
            "29. What is SonarScan and what does it analyze in source code?\n",
            "30. Give me a summary of DevOps Self-Service Centric Terraform Project Structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define evaluation batch runner"
      ],
      "metadata": {
        "id": "eGrT4R3Wr9cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.evaluation import BatchEvalRunner\n",
        "\n",
        "runner = BatchEvalRunner(\n",
        "    {\"faithfulness\": faithfulness_gpt4, \"relevancy\": relevancy_gpt4},\n",
        "    workers=10,\n",
        "    show_progress=True\n",
        ")"
      ],
      "metadata": {
        "id": "IdvoSHfczYLA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_results(key, eval_results):\n",
        "    results = eval_results[key]\n",
        "    correct = 0\n",
        "    for result in results:\n",
        "        if result.passing:\n",
        "            correct += 1\n",
        "    score = correct / len(results)\n",
        "    print(f\"{key} Correct: {correct}. Score: {score}\")\n",
        "    return score"
      ],
      "metadata": {
        "id": "u06cC3F3srKx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of recursive retriever + document agent"
      ],
      "metadata": {
        "id": "FFS4nzsvsCF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = await runner.aevaluate_queries(\n",
        "    recursive_query_engine, queries=question_dataset\n",
        ")\n",
        "\n",
        "print(\"------------------\")\n",
        "score = get_eval_results(\"faithfulness\", eval_results)\n",
        "score = get_eval_results(\"relevancy\", eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGryhDAQnE8X",
        "outputId": "4cdf9374-294d-4dea-bc54-f14cb807a674"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [04:03<00:00,  8.12s/it]\n",
            "100%|██████████| 60/60 [00:03<00:00, 16.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------\n",
            "faithfulness Correct: 30. Score: 1.0\n",
            "relevancy Correct: 30. Score: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of metadata replacement + node sentence window"
      ],
      "metadata": {
        "id": "I0IvBdjmsIUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = await runner.aevaluate_queries(\n",
        "    metadata_query_engine, queries=question_dataset\n",
        ")\n",
        "\n",
        "print(\"------------------\")\n",
        "score = get_eval_results(\"faithfulness\", eval_results)\n",
        "score = get_eval_results(\"relevancy\", eval_results)"
      ],
      "metadata": {
        "id": "Vc3PmNxKD-Dr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8fb8307-6021-43cd-abf0-c8d1435e95fb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:09<00:00,  3.06it/s]\n",
            "100%|██████████| 60/60 [00:03<00:00, 15.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------\n",
            "faithfulness Correct: 25. Score: 0.8333333333333334\n",
            "relevancy Correct: 25. Score: 0.8333333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}